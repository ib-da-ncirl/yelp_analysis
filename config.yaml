
# TensorFlow preferred device; see https://www.tensorflow.org/guide/gpu
# basic options are; '/cpu:0': the CPU of your machine, or '/GPU:0': Short-hand notation for the first GPU of your machine that is visible to TensorFlow.
# setting 'auto' will pick the available device with the most memory
modelling_device: auto

# set maximum memory allocation for gpu in MB
gpu_memory_limit: 1024

# Set if device placements should be logged; true/false
tf_log_device_placement: false

# results folder
results_path_root: ./results

# specify the model to run, the name of an entry in the models list
#run_model: tf_image_eg
#run_model: tf_image_eg_hflip
#run_model: inception_v3_eg
#run_model: inception_v3_eg_hflip
#run_model: inception_v3_eg_hflip_cat_v2
run_model: inception_v3_eg_hflip_ord_v2
#run_model: alexnet
#run_model: xception_eg
# or list of models to run
#run_model:
#  - tf_image_eg_hflip
#  - inception_v3_eg_hflip
#run_model:
#  - inception_v3_eg_hflip_v2
#  - inception_v3_eg_hflip_v2_1
#  - inception_v3_eg_hflip_v2_2
#  - inception_v3_eg_hflip_v2_3
#  - inception_v3_eg_hflip_v2_4
#  - inception_v3_eg_hflip_v2_5
#  - inception_v3_eg_hflip_v2_6
#  - inception_v3_eg_hflip_v2_7
#  - inception_v3_eg_hflip_v2_8
#  - inception_v3_eg_hflip_v2_9
#  - inception_v3_eg_hflip_v2_10
#  - inception_v3_eg_hflip_v2_11
#  - inception_v3_eg_hflip_v2_12
#  - inception_v3_eg_hflip_v2_13
#  - inception_v3_eg_hflip_v2_14
#  - inception_v3_eg_hflip_v2_15
#  - inception_v3_eg_hflip_v2_16
#  - inception_v3_eg_hflip_v2_17
#  - inception_v3_eg_hflip_v2_18
#  - inception_v3_eg_hflip_v2_19
#  - inception_v3_eg_hflip_v2_20
#  - inception_v3_eg_hflip_v2_21
#  - inception_v3_eg_hflip_v2_22
#  - inception_v3_eg_hflip_v2_23
#  - inception_v3_eg_hflip_v2_24
#  - inception_v3_eg_hflip_v2_25  # can only run on its own not enough memory during training run 2
                                  # GeForce GTX 1050 2GB

model_path: ./results/inception_v3_eg_hflip_ord_v2/200809_1622/inception_v3_tl

do_training: true
do_prediction: true


defaults:
  # default settings, all may be over written for a particular model by specifying the value in the model config
  # NOTE: Do not include any image augmentation settings in the default section!

  # path to the photo dataset csv file
  dataset_path: ../project/dataset/photo_dataset_photo20.csv
#  dataset_path: ../project/dataset/photo_dataset.csv
  # specify the limit for the number of photos;
  photo_limit: none
  # number of target classes
  # TODO should probably get number of target classes from dataset
  class_count: 9
  # number of epochs to run a model
  epochs: 15

  # path to the photos folder
  photo_path: ../project/dataset/yelp_photos/photos
  # default image width & height, may be overwritten in model definition by setting 'image_width' & 'image_height'
  # most images are 600px x 400px, so reduce keeping aspect ratio
  image_width: 150
  image_height: 100

  # column in photo dataset csv file that contains the filenames
  x_col: photo_file

  # column in photo dataset csv file that contains the target data
  y_col: stars_cat  # categorical representation; e.g. '1_0' represents 1.0 stars
#  y_col: stars_ord  # ordinal representation; e.g. [1,1,0,0,0,0,0,0,0,0,0] represents 1.0 stars

  # one of "binary", "categorical", "input", "multi_output", "raw", "sparse" or None. Default: "categorical"
  # Mode for yielding the targets:
  # - "binary": 1D numpy array of binary labels
  # - "categorical": 2D numpy array of one-hot encoded labels. Supports multi-label output.
  # - "input": images identical to input images (mainly used to work with autoencoders)
  # - "multi_output": list with the values of the different columns,
  # - "raw": numpy array of values in y_col column(s),
  # - "sparse": 1D numpy array of integer labels
  # - None, no targets are returned
  class_mode: categorical

  # one of "grayscale", "rgb", "rgba". Whether the images will be converted to have 1 or 3 color channels
  color_mode: rgb
  # Size of the batches of data
  batch_size: 32
  # random seed for shuffling and transformations
  seed: 42
  # Fraction of images reserved for validation (sum of training, validation & verification strictly between 0 and 1).
  validation_split: 0.2
  # Fraction of images reserved for verification
  verification_split: 0.05
  # default template for results folder for each model; 'results_path_root/model_name/YYMMDD_HHMM'
  results_path: <results_path_root>/<model_name>/{%y%m%d_%H%M}

  # rescaling factor. Defaults to None. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (after applying all other transformations).
  # Note: eval() is used to evaluate if a string expression is supplied; e.g. '1./255.' = 0.00392156862745098
  rescale: 1./255.

  show_val_loss: false
  save_val_loss: true
  save_summary: true
  save_model: true

# Activation functions
# see https://keras.io/api/layers/activations/ and https://www.tensorflow.org/api_docs/python/tf/keras/activations
# ----------------------------------------------------------------------------------------------------------------
# one of 'elu','exponential','hard_sigmoid','linear','relu','selu','sigmoid','softmax','softplus','softsign','swish' or 'tanh'
#
# current activation settings are
# - gsap_activation
# - logistic layer
#
# Problem type    Output                             Activation function             Loss function
# Regression      Numerical                          Linear (-infinity to infinity)  Mean square error (MSE)
#                 Numerical > 0                      ReLU (0 to infinity)            Mean square error (MSE)
# Classification  Binary                             Sigmoid (0 to 1)                Binary cross entropy (difference between two probability distribution)
#                                                    Tanh (-1 to 1)                  Binary cross entropy (difference between two probability distribution)
# Classification  Single label, multiple classes     Softmax (0 to 1, all sum to 1)  Cross entropy (difference between two probability distribution)
# Classification  Multiple labels, multiple classes  Sigmoid (0 to 1)                Binary cross entropy (difference between two probability distribution)
#
#

# Loss functions
# --------------
# see https://keras.io/api/losses/ and https://www.tensorflow.org/api_docs/python/tf/keras/losses
# some possible values:
# 'binary_crossentropy'             - only two label classes (assumed to be 0 and 1)
# 'categorical_crossentropy'        - labels to be provided in a one_hot representation
# 'sparse_categorical_crossentropy' - labels to be provided as integers
# 'mean_squared_error'

# Optimiser functions
# -------------------
# see https://keras.io/api/optimizers/ and https://www.tensorflow.org/api_docs/python/tf/keras/optimizers
# one of 'adadelta', 'adagrad', 'adam', 'adamax', 'ftrl', 'nadam' , 'rmsprop' or 'sgd'


models:
  - name: tf_image_eg
    desc: TensorFlow Image Classification Tutorial
    # function from models package to call
    function: tf_image_eg
    show_val_loss: false
    save_val_loss: true
    save_summary: true
#    epochs: 15
  - name: tf_image_eg_hflip
    desc: TensorFlow Image Classification Tutorial (Augmentation)
    parent: tf_image_eg

    # Boolean. Randomly flip inputs horizontally.
    horizontal_flip: true
    # Int. Degree range for random rotations.
    rotation_range: 45
    # Float or [lower, upper]. Range for random zoom.
    # If a float, [lower, upper] = [1-zoom_range, 1+zoom_range].
    zoom_range: 0.5
    # Float, 1-D array-like or int
    # - float: fraction of total width, if < 1, or pixels if >= 1.
    # - 1-D array-like: random elements from the array.
    # - int: integer number of pixels from interval (-width_shift_range, +width_shift_range)
    # - With width_shift_range=2 possible values are integers [-1, 0, +1], same as with width_shift_range=[-1, 0, +1], while with width_shift_range=1.0 possible values are floats in the interval [-1.0, +1.0)
    width_shift_range: 0.15
    # Float, 1-D array-like or int
    # - float: fraction of total height, if < 1, or pixels if >= 1.
    # - 1-D array-like: random elements from the array.
    # - int: integer number of pixels from interval (-height_shift_range, +height_shift_range)
    # - With height_shift_range=2 possible values are integers [-1, 0, +1], same as with height_shift_range=[-1, 0, +1], while with height_shift_range=1.0 possible values are floats in the interval [-1.0, +1.0).
    height_shift_range: 0.15
#    # Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)
#    shear_range: 0.0
#    # Boolean. Set input mean to 0 over the dataset, feature-wise.
#    featurewise_center: false
#    # Boolean. Set each sample mean to 0.
#    samplewise_center: false
#    # Boolean. Divide inputs by std of the dataset, feature-wise.
#    featurewise_std_normalization: false
#    # Boolean. Divide each input by its std.
#    samplewise_std_normalization: false
#    # epsilon for ZCA whitening. Default is 1e-6.
#    zca_epsilon: 1e-6
#    # Boolean. Apply ZCA whitening.
#    zca_whitening: false

    # InceptionV3
    # -----------
  - name: inception_v3_eg
    desc: Fine-tune InceptionV3 on a new set of classes
    # function from models package to call
    function: inception_v3_eg
#    epochs: 15
    # path to the photos folder
    photo_path: ../project/dataset/yelp_photos/photos299
    # original InceptionV3 images were 299px x 299px, so use resized copies keeping aspect ratio
    image_width: 299
    image_height: 299

  - name: inception_v3_eg_hflip
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation)
    parent: inception_v3_eg

    # Boolean. Randomly flip inputs horizontally.
    horizontal_flip: true
    # Int. Degree range for random rotations.
    rotation_range: 45
    # Float or [lower, upper]. Range for random zoom.
    # If a float, [lower, upper] = [1-zoom_range, 1+zoom_range].
    zoom_range: 0.5
    # Float, 1-D array-like or int
    # - float: fraction of total width, if < 1, or pixels if >= 1.
    # - 1-D array-like: random elements from the array.
    # - int: integer number of pixels from interval (-width_shift_range, +width_shift_range)
    # - With width_shift_range=2 possible values are integers [-1, 0, +1], same as with width_shift_range=[-1, 0, +1], while with width_shift_range=1.0 possible values are floats in the interval [-1.0, +1.0)
    width_shift_range: 0.15
    # Float, 1-D array-like or int
    # - float: fraction of total height, if < 1, or pixels if >= 1.
    # - 1-D array-like: random elements from the array.
    # - int: integer number of pixels from interval (-height_shift_range, +height_shift_range)
    # - With height_shift_range=2 possible values are integers [-1, 0, +1], same as with height_shift_range=[-1, 0, +1], while with height_shift_range=1.0 possible values are floats in the interval [-1.0, +1.0).
    height_shift_range: 0.15

  - name: inception_v3_eg_hflip_cat_v2
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2 [categorical]
    parent: inception_v3_eg_hflip
    # function from models package to call
    function: inception_v3_eg_v2

    epochs: 15

    # column in photo dataset csv file that contains the target data
    y_col: stars_cat  # categorical representation; e.g. '1_0' represents 1.0 stars
    # one of "binary", "categorical", "input", "multi_output", "raw", "sparse" or None
    class_mode: categorical

    # global spatial average pooling layer
    gsap_units: 1024
    # activation function, see 'Activation functions' above
    gsap_activation: relu
    # Float between 0 and 1. Fraction of the input units to drop.
    gsap_dropout: 0.5

    # global spatial average pooling layer
    gsap2_units: 512
    # activation function, see 'Activation functions' above
    gsap2_activation: relu
    # Float between 0 and 1. Fraction of the input units to drop.
    gsap2_dropout: 0.5

    # logistic layer activation function, see 'Activation functions' above
    log_activation: softmax

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: rmsprop

    # training run 1 loss; see 'Loss functions' above
    run1_loss: categorical_crossentropy

    # training run 2 optimizer, see 'Optimiser functions' above
    run2_optimizer:
      name: sgd
      lr: 0.0001
      momentum: 0.9

    # training run 2 loss; see 'Loss functions' above
    run2_loss: categorical_crossentropy

    # training run 2 number of inception from top to train, e.g. 2 is top 2
    run2_inceptions_to_train: 2

  - name: inception_v3_eg_hflip_ord_v2
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2 [ordinal]
    parent: inception_v3_eg_hflip_cat_v2

    # column in photo dataset csv file that contains the target data
    y_col: stars_ord  # ordinal representation; e.g. [1,1,0...] represents 1.0 stars
    # one of "binary", "categorical", "input", "multi_output", "raw", "sparse" or None
    class_mode: raw

    # logistic layer activation function, see 'Activation functions' above
    log_activation: sigmoid

    # training run 1 loss; see 'Loss functions' above
    run1_loss: categorical_crossentropy

    # training run 2 loss; see 'Loss functions' above
    run2_loss: categorical_crossentropy





  - name: inception_v3_eg_hflip_v2_1
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.1
    parent: inception_v3_eg_hflip_v2

    # Boolean. Randomly flip inputs vertically.
    vertical_flip: true
    # Int. Degree range for random rotations.
    rotation_range: 90
    # Float or [lower, upper]. Range for random zoom.
    # If a float, [lower, upper] = [1-zoom_range, 1+zoom_range].
    zoom_range: 0.25
    # Float, 1-D array-like or int
    # - float: fraction of total width, if < 1, or pixels if >= 1.
    # - 1-D array-like: random elements from the array.
    # - int: integer number of pixels from interval (-width_shift_range, +width_shift_range)
    # - With width_shift_range=2 possible values are integers [-1, 0, +1], same as with width_shift_range=[-1, 0, +1], while with width_shift_range=1.0 possible values are floats in the interval [-1.0, +1.0)
    width_shift_range: 0.05
    # Float, 1-D array-like or int
    # - float: fraction of total height, if < 1, or pixels if >= 1.
    # - 1-D array-like: random elements from the array.
    # - int: integer number of pixels from interval (-height_shift_range, +height_shift_range)
    # - With height_shift_range=2 possible values are integers [-1, 0, +1], same as with height_shift_range=[-1, 0, +1], while with height_shift_range=1.0 possible values are floats in the interval [-1.0, +1.0).
    height_shift_range: 0.05

  - name: inception_v3_eg_hflip_v2_2
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.2
    parent: inception_v3_eg_hflip_v2

    # global spatial average pooling layer
    gsap_units: 512

  - name: inception_v3_eg_hflip_v2_3
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.3
    parent: inception_v3_eg_hflip_v2

    # global spatial average pooling layer
    gsap_units: 256

  - name: inception_v3_eg_hflip_v2_4
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.4
    parent: inception_v3_eg_hflip_v2

    # global spatial average pooling layer
    gsap_units: 128

  - name: inception_v3_eg_hflip_v2_5
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.5
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: elu

  - name: inception_v3_eg_hflip_v2_6
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.6
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: exponential

  - name: inception_v3_eg_hflip_v2_7
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.7
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: hard_sigmoid

  - name: inception_v3_eg_hflip_v2_8
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.8
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: linear

  - name: inception_v3_eg_hflip_v2_9
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.9
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: selu

  - name: inception_v3_eg_hflip_v2_10
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.10
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: sigmoid

  - name: inception_v3_eg_hflip_v2_11
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.11
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: softmax

  - name: inception_v3_eg_hflip_v2_12
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.12
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: softplus

  - name: inception_v3_eg_hflip_v2_13
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.13
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: softsign

  - name: inception_v3_eg_hflip_v2_14
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.14
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: swish

  - name: inception_v3_eg_hflip_v2_15
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.15
    parent: inception_v3_eg_hflip_v2

    # activation function, see 'Activation functions' above
    gsap_activation: tanh

  - name: inception_v3_eg_hflip_v2_16
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.16
    parent: inception_v3_eg_hflip_v2

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: adadelta

  - name: inception_v3_eg_hflip_v2_17
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.17
    parent: inception_v3_eg_hflip_v2

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: adagrad

  - name: inception_v3_eg_hflip_v2_18
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.18
    parent: inception_v3_eg_hflip_v2

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: adam

  - name: inception_v3_eg_hflip_v2_19
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.19
    parent: inception_v3_eg_hflip_v2

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: adamax

  - name: inception_v3_eg_hflip_v2_20
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.20
    parent: inception_v3_eg_hflip_v2

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: ftrl

  - name: inception_v3_eg_hflip_v2_21
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.21
    parent: inception_v3_eg_hflip_v2

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: nadam

  - name: inception_v3_eg_hflip_v2_22
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.22
    parent: inception_v3_eg_hflip_v2

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: sgd

  - name: inception_v3_eg_hflip_v2_23
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.23
    parent: inception_v3_eg_hflip_v2

    # training run 2 number of inception from top to train, e.g. 2 is top 2
    run2_inceptions_to_train: 3

  - name: inception_v3_eg_hflip_v2_24
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.24
    parent: inception_v3_eg_hflip_v2

    # training run 2 number of inception from top to train, e.g. 2 is top 2
    run2_inceptions_to_train: 4

  - name: inception_v3_eg_hflip_v2_25
    desc: Fine-tune InceptionV3 on a new set of classes (Augmentation) Ver. 2.25
    parent: inception_v3_eg_hflip_v2

    # training run 2 number of inception from top to train, e.g. 2 is top 2
    run2_inceptions_to_train: 5


    # ResNet50
    # --------
  - name: resnet50_eg
    desc: Fine-tune ResNet50 on a new set of classes
    # function from models package to call
    function: resnet50_eg
    photo_path: ../project/dataset/yelp_photos/photos224
    # original ResNet images were 224px x 224px, so use resized copies keeping aspect ratio
    image_width: 224
    image_height: 224

    epochs: 1

    # global spatial average pooling layer
    gsap_units: 1024
    # activation function, see 'Activation functions' above
    gsap_activation: relu

    # logistic layer activation function, see 'Activation functions' above
    log_activation: softmax

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: rmsprop

    # training run 2 optimizer, see 'Optimiser functions' above
    run2_optimizer:
      name: sgd
      lr: 0.0001
      momentum: 0.9

    # training run 2, train BatchNormalization layers in base model
    run2_train_bn: true

    # AlexNet50
    # --------
  - name: alexnet
    desc: Single GP AlexNet
    # function from models package to call
    function: alexnet
    photo_path: ../project/dataset/yelp_photos/photos224
    # original ResNet images were 224px x 224px, so use resized copies keeping aspect ratio
    image_width: 224
    image_height: 224

#    epochs: 15

    # global spatial average pooling layer
    gsap_units: 1024
    # activation function, see 'Activation functions' above
    gsap_activation: relu

    # logistic layer activation function, see 'Activation functions' above
    log_activation: softmax

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: rmsprop


    # Xception
    # --------
  - name: xception_eg
    desc: Fine-tune Xception on a new set of classes
    # function from models package to call
    function: xception_eg
    photo_path: ../project/dataset/yelp_photos/photos299
    # original ResNet images were 299px x 299px, so use resized copies keeping aspect ratio
    image_width: 299
    image_height: 299

    epochs: 1

    # global spatial average pooling layer
    gsap_units: 512
    # activation function, see 'Activation functions' above
    gsap_activation: relu

    # logistic layer activation function, see 'Activation functions' above
    log_activation: softmax

    # training run 1 optimizer, see 'Optimiser functions' above
    run1_optimizer: rmsprop

    # training run 2 optimizer, see 'Optimiser functions' above
    run2_optimizer:
      name: sgd
      lr: 0.0001
      momentum: 0.9




